# Transfer Files Tool

A Python script that executes the transfer commands generated by `compare_repos.py` to actually move files from source to target JFrog Artifactory instances.

## 🚀 Features

- **Command Execution**: Executes curl-based and JFrog CLI transfer commands
- **Parallel Processing**: Multi-threaded execution for faster transfers
- **Progress Tracking**: Real-time progress monitoring and logging
- **Resume Capability**: Failed transfers are logged for retry
- **Comprehensive Reporting**: Detailed transfer statistics and reports
- **Dry Run Mode**: Validate commands without executing them
- **Flexible Input**: Process entire output directories or specific transfer files

## 📋 Prerequisites

### For curl commands

- `curl` command available on system
- Network access to source and target Artifactory instances

### For JFrog CLI commands

- JFrog CLI installed: https://jfrog.com/getcli/
- JFrog CLI configured with server profiles matching your config

## 🔧 Installation

The script uses Python's built-in libraries, no additional dependencies required:

```bash
# Make the script executable
chmod +x transfer_files.py

# Or run directly with Python
python transfer_files.py --help
```

## 📝 Command Line Arguments

| Argument             | Short | Required | Description                                    |
| -------------------- | ----- | -------- | ---------------------------------------------- |
| `--output-dir`       | `-o`  | ❌\*     | Output directory containing transfer.txt files |
| `--transfer-file`    | `-f`  | ❌\*     | Specific transfer.txt file to process          |
| `--parallel-workers` | `-p`  | ❌       | Number of parallel workers (default: 5)        |
| `--dry-run`          | `-d`  | ❌       | Validate commands without executing them       |

\*Either `--output-dir` or `--transfer-file` must be specified

## 🚦 Usage Examples

### Basic Usage

```bash
# Process all transfer files in output directory
python transfer_files.py --output-dir out_1234567890

# Process specific transfer file
python transfer_files.py --transfer-file repo1/transfer.txt

# Use more parallel workers for faster transfers
python transfer_files.py --output-dir out_1234567890 --parallel-workers 10
```

### Dry Run Mode

```bash
# Validate commands without executing (recommended first step)
python transfer_files.py --output-dir out_1234567890 --dry-run
```

### Advanced Examples

```bash
# Process specific repository's transfers
python transfer_files.py --transfer-file out_1234567890/my-repo/transfer.txt --parallel-workers 3

# Validate all commands first, then execute
python transfer_files.py --output-dir out_1234567890 --dry-run
python transfer_files.py --output-dir out_1234567890 --parallel-workers 8
```

## 📁 Input Structure

The script expects the output structure generated by `compare_repos.py`:

```
out_<timestamp>/
├── repo1/
│   └── transfer.txt          # Transfer commands for repo1
├── repo2/
│   └── transfer.txt          # Transfer commands for repo2
└── repo3/
    └── transfer.txt          # Transfer commands for repo3
```

### Transfer Command Format

**curl commands:**

```bash
curl -f -s -L -o "file.jar" "https://source.jfrog.io/artifactory/repo/path/file.jar" && curl -f -s -X PUT -T "file.jar" "https://target.jfrog.io/artifactory/repo/path/file.jar" && rm -f "file.jar"
```

**JFrog CLI commands:**

```bash
jf rt download --server-id=source "repo/path/file.jar" "file.jar" && jf rt upload --server-id=target "file.jar" "repo/path/file.jar"
```

## 📊 Output Files

### Generated Files

1. **transfer.log** - Detailed execution log
2. **failed_transfers.log** - Commands that failed (ready to retry)
3. **transfer_report.txt** - Summary statistics and results

### Transfer Report Example

```
============================================================
File Transfer Report
============================================================
Timestamp: 2025-08-08T10:30:45.123456
Output Directory: out_1751376218
Parallel Workers: 5
------------------------------------------------------------
Total Commands: 1500
Successful Transfers: 1485
Failed Transfers: 15
Success Rate: 99.00%
Total Time: 245.67 seconds
Average Time per Transfer: 0.16 seconds
------------------------------------------------------------
Failed commands have been logged to: failed_transfers.log
You can retry failed transfers by running:
  bash failed_transfers.log
```

## 🔄 Retry Failed Transfers

Failed transfers are automatically logged to `failed_transfers.log`:

```bash
# Retry all failed transfers
bash failed_transfers.log

# Or process the failed transfers file again
python transfer_files.py --transfer-file failed_transfers.log
```

## ⚡ Performance Tuning

### Parallel Workers

- **Conservative**: `--parallel-workers 3-5` (default: 5)
- **Moderate**: `--parallel-workers 8-12` (good for most cases)
- **Aggressive**: `--parallel-workers 15-20` (high-performance systems)

### Considerations

- **Network bandwidth**: More workers may saturate bandwidth
- **Server limits**: Artifactory may have connection limits
- **System resources**: More workers consume more memory/CPU

### Timeout Settings

Each transfer command has a 5-minute timeout to prevent hanging:

- Adjust in code if needed for very large files
- Failed transfers due to timeout are logged for retry

## 🐛 Troubleshooting

### Common Issues

**No transfer files found:**

```
WARNING - No transfer files found
```

- Verify the output directory path is correct
- Ensure `compare_repos.py` was run successfully
- Check that transfer.txt files exist in subdirectories

**Permission denied:**

```
ERROR - Failed to read transfer file: Permission denied
```

- Check file permissions: `chmod 644 transfer.txt`
- Ensure you have read access to the directory

**Command execution failed:**

```
Failed transfer - Command returned non-zero exit code
```

- Check authentication credentials
- Verify network connectivity to Artifactory
- Review failed_transfers.log for specific error details

**High failure rate:**

- Check network connectivity
- Verify Artifactory server status
- Review authentication tokens/credentials
- Consider reducing parallel workers
- Check server-side rate limiting

### Debugging

Enable detailed logging by modifying the script:

```python
logging.basicConfig(level=logging.DEBUG)
```

## 🔐 Security Considerations

1. **Credentials**: Transfer commands may contain embedded credentials
2. **Log Files**: Review logs before sharing (may contain sensitive URLs)
3. **Network**: Use HTTPS for all Artifactory communications
4. **File Permissions**: Secure transfer files and logs appropriately

## 🎯 Best Practices

### Before Transfer

1. **Always run dry-run first**: Validate commands before execution
2. **Check disk space**: Ensure sufficient space for temporary files
3. **Network stability**: Use stable network connection for large transfers
4. **Backup verification**: Confirm source files are properly backed up

### During Transfer

1. **Monitor progress**: Watch logs for any issues
2. **Resource usage**: Monitor system resources (CPU, memory, network)
3. **Server health**: Monitor Artifactory server performance

### After Transfer

1. **Review reports**: Check transfer_report.txt for success rates
2. **Retry failures**: Process failed_transfers.log if needed
3. **Verification**: Spot-check transferred files
4. **Cleanup**: Remove temporary files and logs if desired

## 📈 Integration Examples

### CI/CD Pipeline Integration

```bash
#!/bin/bash
# Example CI/CD script

# Step 1: Compare repositories
python compare_repos.py --config prod-to-backup.json --repos-file critical-repos.txt

# Step 2: Validate transfer commands
OUTPUT_DIR=$(ls -1d out_* | sort -r | head -1)
python transfer_files.py --output-dir "$OUTPUT_DIR" --dry-run

# Step 3: Execute transfers
python transfer_files.py --output-dir "$OUTPUT_DIR" --parallel-workers 8

# Step 4: Check success rate
REPORT="$OUTPUT_DIR/transfer_report.txt"
if grep -q "Success Rate: 100.00%" "$REPORT"; then
    echo "All transfers successful!"
    exit 0
else
    echo "Some transfers failed, check logs"
    exit 1
fi
```

### Scheduled Backup Script

```bash
#!/bin/bash
# Automated backup transfer script

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_DIR="/var/log/artifactory-backup/$TIMESTAMP"
mkdir -p "$LOG_DIR"

# Run comparison
python compare_repos.py --config backup-config.json > "$LOG_DIR/compare.log" 2>&1

# Execute transfers
OUTPUT_DIR=$(ls -1d out_* | sort -r | head -1)
python transfer_files.py --output-dir "$OUTPUT_DIR" --parallel-workers 6 > "$LOG_DIR/transfer.log" 2>&1

# Move reports
mv transfer_report.txt "$LOG_DIR/"
mv failed_transfers.log "$LOG_DIR/" 2>/dev/null || true

echo "Backup transfer completed. Logs in: $LOG_DIR"
```

## 🔧 Advanced Configuration

### Custom Timeout Values

Modify the script to adjust timeout settings:

```python
# In execute_transfer_command method
result = subprocess.run(
    command,
    shell=True,
    capture_output=True,
    text=True,
    timeout=600,  # 10 minutes instead of 5
)
```

### Custom Progress Reporting

Modify progress reporting frequency:

```python
# Report progress every 50 transfers instead of 10
if completed % 50 == 0:
    self.logger.info(f"Progress: {completed}/{self.total_commands}")
```

## 🤝 Related Tools

- **compare_repos.py**: Generates the transfer commands
- **JFrog CLI**: Execute JFrog-specific operations
- **curl**: Execute HTTP transfers
- **bash/shell**: Execute generated transfer scripts directly

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.
