#!/usr/bin/env python3

"""
JFrog Artifactory Repository Comparison Tool
===========================================

This script compares artifacts between source and target JFrog Artifactory instances
and generates transfer commands using curl instead of JFrog CLI.

Features:
- Compares files between source and target repositories
- Filters out auto-generated files
- Generates curl-based transfer commands
- Supports parallel processing
- Comprehensive logging
- Configuration file support

Usage:
    python compare_repos.py --config config.json
    python compare_repos.py --source-server source --target-server target
"""

import argparse
import concurrent.futures
import json
import logging
import os
import re
import signal
import sys
import time
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set, Tuple
import requests
from urllib.parse import urljoin, quote

# Suppress known Python 3.13 threading cleanup warnings
warnings.filterwarnings("ignore", message=".*context manager protocol.*")

# Additional Python 3.13 threading cleanup issue suppression
import threading
import atexit


def cleanup_threads():
    """Clean up threads properly on exit."""
    try:
        # Force cleanup of any remaining threads
        for thread in threading.enumerate():
            if thread is not threading.current_thread() and thread.daemon:
                try:
                    thread.join(timeout=0.1)
                except:
                    pass
    except:
        pass


# Register cleanup function
atexit.register(cleanup_threads)

# Global flag for graceful shutdown
_shutdown_requested = False


def signal_handler(signum, frame):
    """Handle interrupt signals gracefully."""
    global _shutdown_requested
    _shutdown_requested = True
    print("\nShutdown requested, cleaning up...", file=sys.stderr)


class SafeThreadPoolExecutor:
    """Thread pool executor with better cleanup for Python 3.13."""

    def __init__(self, max_workers):
        self.max_workers = max_workers
        self.executor = None

    def __enter__(self):
        self.executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_workers
        )
        return self.executor

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.executor:
            try:
                # Cancel all pending futures
                for future in getattr(self.executor, "_threads_queues", {}).keys():
                    try:
                        future.cancel()
                    except:
                        pass

                # Shutdown with wait=False to avoid blocking
                self.executor.shutdown(wait=False)

                # Give threads a moment to finish
                time.sleep(0.1)

            except Exception as e:
                # Silently handle any cleanup issues
                pass
            finally:
                self.executor = None


class ArtifactoryComparer:
    """
    Main class for comparing artifacts between JFrog Artifactory instances.
    """

    def __init__(
        self,
        config_file: str = None,
        source_server: str = None,
        target_server: str = None,
        repos_file: str = None,
    ):
        """
        Initialize the comparer with configuration.

        Args:
            config_file: Path to configuration file
            source_server: Source server ID (if not using config file)
            target_server: Target server ID (if not using config file)
            repos_file: Path to file containing repository names to compare
        """
        self.config = self._load_config(config_file, source_server, target_server)
        self.repos_file = repos_file
        self.output_dir = f"out_{int(time.time())}"

        # Create output directory
        Path(self.output_dir).mkdir(exist_ok=True)

        self.logger = self._setup_logging()

        # Files that are auto-generated by JFrog Artifactory and should be ignored
        self.skipped_files = {
            "repository.catalog",
            "maven-metadata.xml",
            "Packages.bz2",
            ".gemspec.rz",
            "Packages.gz",
            "Release",
            ".json",
            "Packages",
            "by-hash",
            "filelists.xml.gz",
            "other.xml.gz",
            "primary.xml.gz",
            "repomd.xml",
            "repomd.xml.asc",
            "repomd.xml.key",
        }

        # Patterns for auto-generated paths that should be ignored
        self.skipped_patterns = [
            r"^\.npm",
            r"^\.jfrog",
            r"^\.pypi",
            r"^\.composer",
            r"^index\.yaml$",
            r"^versions$",
            r"_uploads",
        ]

        self.logger.info(
            f"Initialized repository comparer with output directory: {self.output_dir}"
        )

    def _load_config(
        self, config_file: str, source_server: str, target_server: str
    ) -> Dict:
        """Load configuration from file or command line arguments."""
        if config_file and os.path.exists(config_file):
            with open(config_file, "r") as f:
                config = json.load(f)
            return config

        if source_server and target_server:
            source_token = (
                os.getenv(f"{source_server.upper()}_TOKEN", "")
                or os.getenv("SOURCE_ARTIFACTORY_TOKEN", "")
                or os.getenv("SOURCE_TOKEN", "")
            )
            source_username = (
                os.getenv(f"{source_server.upper()}_USER", "")
                or os.getenv("SOURCE_ARTIFACTORY_USER", "")
                or os.getenv("SOURCE_USER", "")
            )
            source_password = (
                os.getenv(f"{source_server.upper()}_PASS", "")
                or os.getenv("SOURCE_ARTIFACTORY_PASS", "")
                or os.getenv("SOURCE_PASS", "")
            )

            # For target server - try both specific and generic environment variables
            target_token = (
                os.getenv(f"{target_server.upper()}_TOKEN", "")
                or os.getenv("TARGET_ARTIFACTORY_TOKEN", "")
                or os.getenv("TARGET_TOKEN", "")
            )
            target_username = (
                os.getenv(f"{target_server.upper()}_USER", "")
                or os.getenv("TARGET_ARTIFACTORY_USER", "")
                or os.getenv("TARGET_USER", "")
            )
            target_password = (
                os.getenv(f"{target_server.upper()}_PASS", "")
                or os.getenv("TARGET_ARTIFACTORY_PASS", "")
                or os.getenv("TARGET_PASS", "")
            )

            return {
                "source_server": source_server,
                "target_server": target_server,
                "servers": {
                    source_server: {
                        "url": f"https://{source_server}",
                        "token": source_token,
                        "username": source_username,
                        "password": source_password,
                    },
                    target_server: {
                        "url": f"https://{target_server}",
                        "token": target_token,
                        "username": target_username,
                        "password": target_password,
                    },
                },
                "parallel_workers": 20,
                "request_timeout": 30,
                "retry_attempts": 3,
            }

        raise ValueError(
            "Either config_file or both source_server and target_server must be provided"
        )

    def _setup_logging(self) -> logging.Logger:
        """Setup logging configuration."""
        log_level = self.config.get("log_level", "INFO").upper()
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

        # Configure root logger
        logging.basicConfig(
            level=getattr(logging, log_level),
            format=log_format,
            handlers=[
                logging.FileHandler(f"{self.output_dir}/compare_repos.log"),
                logging.StreamHandler(sys.stdout),
            ],
        )

        return logging.getLogger(__name__)

    def _get_auth_headers(self, server_id: str) -> Dict[str, str]:
        """Get authentication headers for the specified server."""
        server_config = self.config["servers"][server_id]
        headers = {"Content-Type": "application/json"}

        if server_config.get("token"):
            headers["Authorization"] = f"Bearer {server_config['token']}"
        elif server_config.get("username") and server_config.get("password"):
            import base64

            credentials = base64.b64encode(
                f"{server_config['username']}:{server_config['password']}".encode()
            ).decode()
            headers["Authorization"] = f"Basic {credentials}"
        else:
            self.logger.warning(f"No authentication configured for server {server_id}")

        return headers

    def _make_request(
        self,
        server_id: str,
        endpoint: str,
        method: str = "GET",
        data: str = None,
        params: Dict = None,
    ) -> requests.Response:
        """Make HTTP request to JFrog Artifactory API."""
        server_config = self.config["servers"][server_id]
        url = urljoin(server_config["url"], endpoint)
        headers = self._get_auth_headers(server_id)

        timeout = self.config.get("request_timeout", 30)
        retry_attempts = self.config.get("retry_attempts", 3)

        for attempt in range(retry_attempts):
            try:
                if method.upper() == "GET":
                    response = requests.get(
                        url, headers=headers, params=params, timeout=timeout
                    )
                elif method.upper() == "POST":
                    if data:
                        headers["Content-Type"] = "text/plain"
                    response = requests.post(
                        url, headers=headers, data=data, timeout=timeout
                    )
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                response.raise_for_status()
                return response

            except requests.exceptions.RequestException as e:
                self.logger.warning(
                    f"Request attempt {attempt + 1} failed for {url}: {str(e)}"
                )
                if attempt == retry_attempts - 1:
                    raise
                time.sleep(2**attempt)  # Exponential backoff

    def get_repositories(self, server_id: str) -> List[str]:
        """Get list of local repositories from Artifactory."""
        self.logger.info(f"Fetching repositories from {server_id}")

        try:
            response = self._make_request(
                server_id, "/artifactory/api/repositories", params={"type": "local"}
            )
            repositories = [repo["key"] for repo in response.json()]
            self.logger.info(f"Found {len(repositories)} repositories in {server_id}")
            return repositories
        except Exception as e:
            self.logger.error(
                f"Failed to fetch repositories from {server_id}: {str(e)}"
            )
            raise

    def read_repositories_from_file(self, repos_file: str) -> List[str]:
        """
        Read repository names from a text file.

        Args:
            repos_file: Path to text file containing repository names (one per line)

        Returns:
            List of repository names
        """
        if not os.path.exists(repos_file):
            raise FileNotFoundError(f"Repository file not found: {repos_file}")

        repositories = []
        try:
            with open(repos_file, "r") as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    # Skip empty lines and comments
                    if line and not line.startswith("#"):
                        repositories.append(line)

            self.logger.info(f"Read {len(repositories)} repositories from {repos_file}")
            return repositories

        except Exception as e:
            self.logger.error(
                f"Failed to read repositories from {repos_file}: {str(e)}"
            )
            raise

    def filter_existing_repositories(
        self, requested_repos: List[str], available_repos: List[str]
    ) -> List[str]:
        """
        Filter requested repositories to only include those that exist on the source server.

        Args:
            requested_repos: List of repository names requested for comparison
            available_repos: List of repository names available on source server

        Returns:
            List of repositories that exist and will be compared
        """
        available_set = set(available_repos)
        existing_repos = []
        missing_repos = []

        for repo in requested_repos:
            if repo in available_set:
                existing_repos.append(repo)
            else:
                missing_repos.append(repo)

        if missing_repos:
            self.logger.warning(
                f"The following repositories were not found on source server: {missing_repos}"
            )

        self.logger.info(
            f"Found {len(existing_repos)} out of {len(requested_repos)} requested repositories"
        )
        return existing_repos

    def get_repository_files(
        self, server_id: str, repo_name: str
    ) -> List[Tuple[str, str]]:
        """
        Get list of ALL files in repository with their SHA2 checksums.

        This method performs a RECURSIVE scan of the entire repository,
        returning every file in every subdirectory at any depth level.

        Uses Artifactory Storage API:
        GET /artifactory/api/storage/{repoKey}/{folder-path}?list[&deep=0/1][&depth=n][&listFolders=0/1][&mdTimestamps=0/1][&includeRootPath=0/1]

        Parameters used:
        - list=1: Enable file listing
        - deep=1: Recursive listing (gets ALL files in ALL subdirectories)
        - depth=n: Optional - limits recursion to n levels (omitted = unlimited)
        - listFolders=0: Only return files, not folders
        - mdTimestamps=0: Skip metadata timestamps for better performance

        Depth examples:
        - depth=0: Only root directory files
        - depth=1: Root + 1 level of subdirectories
        - depth=2: Root + 2 levels of subdirectories
        - No depth parameter: Unlimited recursion (current behavior)

        Returns:
            List of tuples (file_path, sha2_checksum) for ALL files in the repository
        """
        self.logger.debug(f"Fetching files from repository {repo_name} on {server_id}")

        try:
            endpoint = f"/artifactory/api/storage/{repo_name}"
            response = self._make_request(
                server_id,
                endpoint,
                params={
                    "list": "1",  # Enable file listing
                    "deep": "1",  # Recursive listing - gets ALL files in ALL subdirectories
                    "listFolders": "0",  # Don't list folders, only files
                    "mdTimestamps": "0",  # Don't include metadata timestamps for better performance
                },
            )

            files = []
            data = response.json()

            # Check if the response contains the expected file listing
            if "files" in data and isinstance(data["files"], list):
                for file_info in data["files"]:
                    if not isinstance(file_info, dict):
                        continue

                    file_path = file_info.get("uri", "").lstrip("/")
                    sha2 = file_info.get("sha2", "")

                    # Only include actual files with SHA2 checksums
                    if file_path and sha2:
                        files.append((file_path, sha2))
            else:
                self.logger.warning(
                    f"Unexpected API response structure for repository {repo_name}"
                )
                self.logger.debug(f"Response data: {data}")

            # Log some sample file paths to verify recursive listing is working
            if files and self.logger.isEnabledFor(logging.DEBUG):
                sample_files = files[:5]  # First 5 files
                self.logger.debug(f"Sample file paths from {repo_name}:")
                for file_path, sha2 in sample_files:
                    self.logger.debug(f"  {file_path} (SHA2: {sha2[:16]}...)")

            self.logger.debug(f"Found {len(files)} files in {repo_name}")
            return files

        except Exception as e:
            self.logger.error(
                f"Failed to fetch files from {repo_name} on {server_id}: {str(e)}"
            )
            return []

    def should_skip_file(self, file_path: str) -> bool:
        """
        Check if a file should be skipped based on patterns and filename.

        Args:
            file_path: Path of the file to check

        Returns:
            True if file should be skipped, False otherwise
        """
        filename = os.path.basename(file_path)

        # Check if filename is in skipped files list
        if filename in self.skipped_files:
            return True

        # Check if path matches any skipped patterns
        for pattern in self.skipped_patterns:
            if re.match(pattern, file_path):
                return True

        return False

    def compare_repository(self, repo_name: str) -> Dict:
        """
        Compare files between source and target repository.

        Args:
            repo_name: Name of the repository to compare

        Returns:
            Dictionary containing comparison results
        """
        self.logger.info(f"Comparing repository: {repo_name}")

        try:
            # Create output directory for this repository
            repo_output_dir = Path(self.output_dir) / repo_name
            repo_output_dir.mkdir(exist_ok=True)

            # Get files from both servers
            source_files = self.get_repository_files(
                self.config["source_server"], repo_name
            )
            target_files = self.get_repository_files(
                self.config["target_server"], repo_name
            )

            # Convert to sets for comparison (file_path, sha2)
            source_set = set(source_files)
            target_set = set(target_files)

            # Find files that are in source but not in target (or have different checksums)
            diff_files = source_set - target_set

            # Filter out files that should be skipped
            filtered_diff_files = []
            for file_path, sha2 in diff_files:
                if not self.should_skip_file(file_path):
                    filtered_diff_files.append(file_path)

            # Generate results
            result = {
                "repo_name": repo_name,
                "total_source_files": len(source_files),
                "total_target_files": len(target_files),
                "total_diff_files": len(diff_files),
                "filtered_diff_files": len(filtered_diff_files),
                "diff_files": filtered_diff_files,
            }

            # Write results to files
            self._write_repository_results(repo_output_dir, result)

            self.logger.info(
                f"Repository {repo_name} comparison completed. "
                f"Found {len(filtered_diff_files)} files to transfer"
            )

            return result

        except Exception as e:
            self.logger.error(f"Failed to compare repository {repo_name}: {str(e)}")
            return {"repo_name": repo_name, "error": str(e), "diff_files": []}

    def _write_repository_results(self, repo_output_dir: Path, result: Dict):
        """Write repository comparison results to files."""
        repo_name = result["repo_name"]
        diff_files = result.get("diff_files", [])

        if not diff_files:
            return

        # Write list of different files
        diff_file_path = repo_output_dir / f"{repo_name}.txt"
        with open(diff_file_path, "w") as f:
            f.write("-" * 50 + "\n")
            f.write(f"Files diff from source - Repo [{repo_name}]\n")
            f.write("-" * 50 + "\n")
            for i, file_path in enumerate(diff_files, 1):
                f.write(f"{i:6d}  {file_path}\n")

        # Write transfer commands
        transfer_file_path = repo_output_dir / "transfer.txt"
        with open(transfer_file_path, "w") as f:
            for file_path in diff_files:
                # Generate curl commands for download and upload
                download_cmd = self._generate_download_command(repo_name, file_path)
                upload_cmd = self._generate_upload_command(repo_name, file_path)
                cleanup_cmd = f'rm -f "{os.path.basename(file_path)}"'

                f.write(f"{download_cmd} && {upload_cmd} && {cleanup_cmd}\n")

        # Append to full list log
        fulllist_path = Path(self.output_dir) / "fulllist.log"
        with open(fulllist_path, "a") as f:
            for i, file_path in enumerate(diff_files, 1):
                f.write(f"{i:6d}  {file_path}\n")

    def _generate_download_command(self, repo_name: str, file_path: str) -> str:
        """Generate curl command to download file from source server."""
        source_config = self.config["servers"][self.config["source_server"]]
        encoded_path = quote(file_path, safe="/")
        url = f"{source_config['url']}/artifactory/{repo_name}/{encoded_path}"

        # Build curl command with authentication
        cmd_parts = ["curl", "-f", "-s", "-L"]

        if source_config.get("token"):
            cmd_parts.extend(
                ["-H", f"\"Authorization: Bearer {source_config['token']}\""]
            )
        elif source_config.get("username") and source_config.get("password"):
            cmd_parts.extend(
                ["-u", f"\"{source_config['username']}:{source_config['password']}\""]
            )

        cmd_parts.extend(["-o", f'"{os.path.basename(file_path)}"', f'"{url}"'])

        return " ".join(cmd_parts)

    def _generate_upload_command(self, repo_name: str, file_path: str) -> str:
        """Generate curl command to upload file to target server."""
        target_config = self.config["servers"][self.config["target_server"]]
        encoded_path = quote(file_path, safe="/")
        url = f"{target_config['url']}/artifactory/{repo_name}/{encoded_path}"

        # Build curl command with authentication
        cmd_parts = ["curl", "-f", "-s", "-X", "PUT"]

        if target_config.get("token"):
            cmd_parts.extend(
                ["-H", f"\"Authorization: Bearer {target_config['token']}\""]
            )
        elif target_config.get("username") and target_config.get("password"):
            cmd_parts.extend(
                ["-u", f"\"{target_config['username']}:{target_config['password']}\""]
            )

        cmd_parts.extend(["-T", f'"{os.path.basename(file_path)}"', f'"{url}"'])

        return " ".join(cmd_parts)

    def run_comparison(self):
        """Run the full repository comparison process."""
        start_time = time.time()
        self.logger.info("Starting repository comparison process")

        try:
            # Get list of repositories to compare
            if self.repos_file:
                # Read repositories from file
                requested_repos = self.read_repositories_from_file(self.repos_file)

                # Get available repositories from source server for validation
                available_repos = self.get_repositories(self.config["source_server"])

                # Filter to only include existing repositories
                repositories = self.filter_existing_repositories(
                    requested_repos, available_repos
                )

                if not repositories:
                    self.logger.error(
                        "No valid repositories found from the specified file"
                    )
                    return

                self.logger.info(
                    f"Comparing {len(repositories)} repositories from file: {self.repos_file}"
                )
            else:
                # Get all repositories from source server
                repositories = self.get_repositories(self.config["source_server"])

                if not repositories:
                    self.logger.warning("No repositories found on source server")
                    return

                self.logger.info(
                    f"Comparing all {len(repositories)} repositories from source server"
                )

            # Initialize summary tracking
            total_files_to_transfer = 0
            completed_repos = 0
            failed_repos = 0

            # Process repositories with parallel workers
            max_workers = self.config.get("parallel_workers", 20)

            try:
                with SafeThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_repo = {
                        executor.submit(self.compare_repository, repo): repo
                        for repo in repositories
                    }

                    for future in concurrent.futures.as_completed(future_to_repo):
                        repo = future_to_repo[future]
                        try:
                            result = future.result()
                            if "error" not in result:
                                total_files_to_transfer += result.get(
                                    "filtered_diff_files", 0
                                )
                                completed_repos += 1
                            else:
                                failed_repos += 1
                        except Exception as e:
                            self.logger.error(
                                f"Repository {repo} generated an exception: {str(e)}"
                            )
                            failed_repos += 1
            except Exception as e:
                self.logger.error(f"Thread pool execution error: {str(e)}")
                # Continue with summary generation even if threading had issues

            # Generate summary
            self._generate_summary(
                repositories, total_files_to_transfer, completed_repos, failed_repos
            )

            elapsed_time = time.time() - start_time
            self.logger.info(
                f"Repository comparison completed in {elapsed_time:.2f} seconds"
            )
            self.logger.info(f"Total files to transfer: {total_files_to_transfer}")

        except Exception as e:
            self.logger.error(f"Repository comparison failed: {str(e)}")
            raise

    def _generate_summary(
        self, repositories: List[str], total_files: int, completed: int, failed: int
    ):
        """Generate summary report."""
        summary_path = Path(self.output_dir) / "summary.txt"

        with open(summary_path, "w") as f:
            f.write("=" * 60 + "\n")
            f.write("JFrog Artifactory Repository Comparison Summary\n")
            f.write("=" * 60 + "\n")
            f.write(f"Timestamp: {datetime.now().isoformat()}\n")
            f.write(f"Source Server: {self.config['source_server']}\n")
            f.write(f"Target Server: {self.config['target_server']}\n")
            f.write(f"Output Directory: {self.output_dir}\n")
            f.write("-" * 60 + "\n")
            f.write(f"Total Repositories Processed: {len(repositories)}\n")
            f.write(f"Successfully Completed: {completed}\n")
            f.write(f"Failed: {failed}\n")
            f.write(f"Total Files to Transfer: {total_files}\n")
            f.write("-" * 60 + "\n")
            f.write("\nTransfer Commands Usage:\n")
            f.write(
                '- Execute all transfers: find ./ -name "transfer.txt" -exec cat {} \\; | sh\n'
            )
            f.write(
                '- Count transfer commands per repo: find ./ -name "transfer.txt" -exec wc -l {} +\n'
            )
            f.write(
                '- Total transfer commands: find ./ -name "transfer.txt" -exec cat {} \\; | wc -l\n'
            )
            f.write(
                "- View diff files for specific repo: cat <repo-name>/<repo-name>.txt\n"
            )
            f.write("- View all diff files: cat fulllist.log\n")

        self.logger.info(f"Summary report generated: {summary_path}")


def main():
    """Main entry point for the script."""
    # Register signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    parser = argparse.ArgumentParser(
        description="Compare JFrog Artifactory repositories and generate transfer commands",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Using configuration file
  python compare_repos.py --config config.json

  # Using command line arguments
  python compare_repos.py --source-server myartifactory-source.jfrog.io --target-server myartifactory-target.jfrog.io

  # With environment variables for authentication
  export MYARTIFACTORY_SOURCE_TOKEN="your-source-token"
  export MYARTIFACTORY_TARGET_TOKEN="your-target-token"
  python compare_repos.py --source-server myartifactory-source --target-server myartifactory-target

  # Compare only specific repositories from a file
  python compare_repos.py --config config.json --repos-file repos.txt
        """,
    )

    parser.add_argument(
        "--config", "-c", help="Path to configuration file (JSON format)"
    )

    parser.add_argument("--source-server", "-s", help="Source Artifactory server ID")

    parser.add_argument("--target-server", "-t", help="Target Artifactory server ID")

    parser.add_argument(
        "--repos-file",
        "-r",
        help="Path to text file containing repository names (one per line) to compare. If not provided, all repositories will be compared.",
    )

    args = parser.parse_args()

    if not args.config and not (args.source_server and args.target_server):
        parser.error(
            "Either --config or both --source-server and --target-server are required"
        )

    try:
        comparer = ArtifactoryComparer(
            config_file=args.config,
            source_server=args.source_server,
            target_server=args.target_server,
            repos_file=args.repos_file,
        )
        comparer.run_comparison()

    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)
    finally:
        # Force garbage collection to help with thread cleanup
        import gc

        gc.collect()

        # Temporarily redirect stderr to suppress threading cleanup messages
        import os

        original_stderr = os.dup(2)
        null_fd = os.open(os.devnull, os.O_WRONLY)
        os.dup2(null_fd, 2)

        # Small delay to allow cleanup
        time.sleep(0.1)

        # Restore stderr
        os.dup2(original_stderr, 2)
        os.close(null_fd)
        os.close(original_stderr)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nOperation cancelled by user", file=sys.stderr)
        sys.exit(1)
    except SystemExit:
        raise
    except Exception as e:
        print(f"Unexpected error: {str(e)}", file=sys.stderr)
        sys.exit(1)
